---
published: false
---
Welcome back readers! In the last post, I started explaining the background for the simple game that I've come to think of as 'Employee's Dilemma'. This time, I'm going to show you the sim in action and explain why the results got me so excited. But first, I'm guessing a bunch of you are wondering: 'why _employee's_ dilemma?' Is he saying that employees are like prisoners?

In fact, no. While the parallel amuses me, the reason why I picked this name is because real, positive coordination in the workplace almost always requires more effort than simply making the choice to do what's asked. Great companies are made when the people that comprise them put in effort to make their company better than it was when they joined. I wanted to capture the sense that real, meaningful coordination, particularly around work, involves making choices that are often difficult, subtle, and requiring of at least a glimmer of personal agency.

And here's the point that makes that clear: put the 'employee's dilemma' into a simple iterative simulation and defection immediately and comprenehsively wins. All attempts to coordinate in the simplest possible version of the model are doomed. 

Why is this? Because in a classic Prisoner's Dilemma model, it's hard enough to find conditions under which cooperation can survive. When you make it three times harder for cooperation to happen, it doesn't stand a chance. 

But that's why I like this game. You can't get away with using an off-the-shelf modeling approach. This is the kind of dirty, hybird game that many professional complex systems system modelers won't touch. There are too many assumptions that you have to make to get something publishable out of it. However, I wasn't interested in publishing. I was interested in what made human coordination work. How come the results in a basic computer model are so very different from what you see when you put the same game in a room full of humans?

A few more debriefs from applied improv workshops gave me plenty of clues. People were applying _heuristics_ when they interacted with each other during the game. Two really clear ones stood out. First, when a person defected against them, they remembered and retaliated, even if it came with a personal cos. After all, they had nothing to lose. Secondly, if someone cooperated, they remembered that pattern and tried to use it again. What would happen, I wondered, if I took those two super-simple rules and added them to my agents. It meant adding some extra intelligence to my simulated people to allow them to recognize each other, but that didn't require much work. I added in that feature, set the sim running, and watched what happened. If you like you can do the same thing here in this Javascript version of the sim I've made for you to run.

In the following panels, I've built a little army of software robots represented by the rows of pie-charts. Each disk is the mind of an agent, showing their preference for the three different kinds of cooperative behavior (red, blue and green) and Darth-Vader-black showing their willingness to be mean. At the start of the simulation nobody has any preferences, but click on the model and things change.

I've also included a timeline that will show you how much the behaviors are preferred in the population as time passes. That extra yellow line you see measures the level of happiness in the population. How much do people actually like the team they're in? A high score is good, a low one means everyone is miserable. Click on the sim once to start, again to stop, and a third time to reset. 



Lo and behold, with these two simple additional rules, something wonderful happens. My agents go from being black-hearted defectors to something a little like a human team. At first, the agents have no idea what to do. Their behaviors are all over the place. Defection slowly starts to dominate. After a while, that pattern of habitual retaliation settles in as a norm. Nobody is being particularly nice to each other. They're all scoring points. But meanwhile, in the background, among those glimmers of niceness that remain, one particular choice of action starts to win out over the others. And when that becomes clear, suddenly everyone starts to get on board with it. A single, shared approach suddenly spreads across the team like wildfire. After that, things get lovely. A team has been born. Agents are now cooperating with each other all over the place because they know how.

Does this pattern sound familiar to you? If you work in HR or managment, it should, because this is Tuckman's original [four stages of group development](https://en.wikipedia.org/wiki/Tuckman%27s_stages_of_group_development) from his seminal 1965 paper. To my knowledge, there's never been a testable scientific theory for why his model might be true, despite the fact that it gets referenced by management schools all across the planet to this day. But hey, now there is! 

With just a little tinkering and a few assumptions we seem to have reproduced an effect that's been observed in countless businesses for the last fifty years. Even if something else is going on that we haven't accounted for, we certainly have a model that's suggestive enough for us to play with to see if we can learn something. After all, what's the point of having a tool that seemingly reproduces some interesting facet of human behavior with minimal effort if you don't extend it to see what it can do, and how you can use it to make the world a better place? And this is where leadership comes in. In the next post, I'll show you how.

