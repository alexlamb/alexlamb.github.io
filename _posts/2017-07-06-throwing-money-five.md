---
published: false
---

This time, I don't have any simulations to share. Instead, I want to reflect on the sims that have already appeared in this series and follow through on a promise I made last time: to reveal what I thought was the deeper truth that these economic models provide. 

But to make that point, it'll help if I first cover a few other bases about what I've been trying to do.

## Sims are simple
The first thing I want to do is encourage you to look at the page source for these posts and check out the code. Maybe you're not a coder and you don't care, but even so, it's worth taking a look at just how much complexity there *isn't* in these simulations. They're tiny. Furthermore, they don't require much effort to understand. I want you to look because I want you to see that the frontier of science is *right in front of you*.

Sure, there are plenty of scientific disciplines in which you have to get a PhD and study for years to make a difference, but simulation science isn't one of them. And there are so many possible sims you can build that the chance of you writing one that the world has never seen is remarkably high. 

Does that mean that everything you write will be wanted in science journals across the world? Of course not. But unless you're trying to be a career scientist, who cares? You don't have to be part of some grand department to be a seeker after truth. We live in an age when the tools for building thought experiments and testing our rational assumptions have never been better. And yet we're seeing those very tools be used in a way that erodes reason instead of supporting it. The right solution isn't to trust science to someone in a lab who we suspect is cleverer than we are. It's to engage, because we can.

I don't have a PhD. I got a C in my Physics A Level at school in England. I did no physics at university. And yet I've done quantum gravity research. How come? Just two things: curiosity and writing code for scientists without getting paid. 

## Why bother?
The next point I want to cover is about the reason for it all. You might say *why bother with all this?*. After all, these models are simple and people are complicated. How can we possibly hope to capture what makes the rich, vivid, challenging mess that is human society tick with just a couple of pages of code?

The answer is simple. We don't try to model *all* of it. Just certain important parts. And furthermore, the idea that you can't model things like human society presumes that if you put a lot of complicated people together that the combined result must necessarily be *more* complicated. 

But the world doesn’t work that way and we know it. Consider traffic patterns. Every driver of a car is a complex, nuanced individual with a completely different set of desires and goals to the others around her. However, all traffic jams look pretty much the same. 

This is because every pattern in the world that’s *emergent* - that seems to grow out of the movement of many elements - operates as a kind of filter. Only certain actions that one person can take will result in visible transformations when we look at everyone together. The rest of their differences get washed out. 

Human social systems often work like this. Whenever you vote or buy soap, the options presented to you are finite. The reasons for your choices can be totally different from everyone else's, but effects will still aggregate. Just having finite choices, or having to compensate for the choices of others, means that the behavior of the social whole is often different from its parts.

## Testing ideas makes us wiser
There's another key reason to bother, which hooks up with something I mentioned in the last post. And it's this: even if the models we make don't capture the phenomena we actually see in the world, they still force us to test our ideas about the world, and figure out what our ideas actually entail.

There has recently been some lovely psychology research that shows how people imagine they know more than they [do](https://www.economist.com/news/books-and-arts/21720262-human-cleverness-arises-distributing-knowledge-between-minds-making-people-think). And this gap in our understanding of the world is never more acute than when we're making decisions about the society we're a part of, or systems in the world that are far larger than we are, like the environment for instance. We usually never our ideas about such things because we imagine they can’t be tested. But if an idea, when expressed in a model, doesn’t behave the way that guessed, then there *must* be something we’re missing. 

What this means is that costly experiments and laborious data collection aren’t always necessary to improve our understanding of the world. They certainly help, but the easiest, cheapest place to refine our thinking is to use the tools right in front of us. Armchair pontification is cheap. Model-driven pontification is slight less cheap, which is a great start. 

## Look deep
Which brings me to my core point about the simulations I've been posting this week.


Don’t just look at the specifics. Look at the patterns: symmetry breaking.
Wealth distributions are the clue.
Why do we expect markets to produce magic answers?
